{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgUjlFTs5X-2"
   },
   "source": [
    "<font size=\"6\"><font face=\"Bookman Old Style\"><b><center>Question 1</center></b><br>\n",
    "<font size=\"5\"><b>Develop python code for the below requirements:</b><br>\n",
    "<font size=\"3\">\n",
    "1. Read the above news article text from a text file.<br>\n",
    "2. Normalize the text by case-folding and print it.<br>\n",
    "3. Remove punctuation from the text and print:<br>\n",
    "    a) Text after removal of punctuation.<br>\n",
    "    b) List of punctuation that were removed.<br>\n",
    "4. Remove Stop Words using Stopwords English corpus and print:<br>\n",
    "    a) List of stopwords<br>\n",
    "    b) List of words after removing stopwords.<br>\n",
    "5. Tokenize the text:<br>\n",
    "    a) Into sentences and print the list of tokenized sentences.<br>\n",
    "    b) Into words and print the list of tokenized words.<br>\n",
    "6. Perform stemming of words using Porterâ€™s stemming and print the list of all word-stem pair.<br>\n",
    "    For example: studies-studi<br>\n",
    "7. Perform lemmatization on the words using Wornet Lemmatizer and print the list of all word-\n",
    "lemma pair.<br>\n",
    "    For example: studies-study<br>\n",
    "8. Perform parts-of-speech tagging and print the list of word-POS pair.<br>\n",
    "9. Perform Named-Entity recognition on the text and print the word-NE pair:<br>\n",
    "    a) Using ne_chunk<br>\n",
    "    b) Using spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "M8PujupO5VMi",
    "outputId": "3c5baac1-5145-41dd-b7a3-76cf056da19d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Citing high fuel prices, United Airlines said on Friday, it has increased fares by $6 per round trip on\\nflights to some cities also served by lower-cost carriers. American Airlines, a unit of Corp.,\\nimmediately matched the move, spokesman Tim Wagner said. United, a unit of Corp., said the\\nincrease took effect on Thursday and applies to most routes where it competes against discount\\ncarriers, such as Chicago to Dallas and Denver to San Francisco. Jane Villanueva of United, a unit of\\nUnited Airlines Holding, said the fare applies to the Chicago route. Washington was born into slavery\\non the farm of James Burroughs. Washington went up 2 games to 1 in the four-game series. Blair\\narrived in Washington for what may well be his last state visit. In June, Washington passed a primary\\nseatbelt law.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"\"\"Citing high fuel prices, United Airlines said on Friday, it has increased fares by $6 per round trip on\n",
    "flights to some cities also served by lower-cost carriers. American Airlines, a unit of Corp.,\n",
    "immediately matched the move, spokesman Tim Wagner said. United, a unit of Corp., said the\n",
    "increase took effect on Thursday and applies to most routes where it competes against discount\n",
    "carriers, such as Chicago to Dallas and Denver to San Francisco. Jane Villanueva of United, a unit of\n",
    "United Airlines Holding, said the fare applies to the Chicago route. Washington was born into slavery\n",
    "on the farm of James Burroughs. Washington went up 2 games to 1 in the four-game series. Blair\n",
    "arrived in Washington for what may well be his last state visit. In June, Washington passed a primary\n",
    "seatbelt law.\"\"\"\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjIY5xqE6GkZ"
   },
   "source": [
    "<font size=\"4\"><font face=\"Bookman Old Style\"><b>Question 1</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FGoFImEM5dUx"
   },
   "outputs": [],
   "source": [
    "with open('article.txt', 'w') as file:\n",
    "    for sentence in text:\n",
    "        file.write(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bsare83G5mKG",
    "outputId": "39a41b05-aac9-4f82-8f2a-ec0cb077ffc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citing high fuel prices, United Airlines said on Friday, it has increased fares by $6 per round trip on\n",
      "flights to some cities also served by lower-cost carriers. American Airlines, a unit of Corp.,\n",
      "immediately matched the move, spokesman Tim Wagner said. United, a unit of Corp., said the\n",
      "increase took effect on Thursday and applies to most routes where it competes against discount\n",
      "carriers, such as Chicago to Dallas and Denver to San Francisco. Jane Villanueva of United, a unit of\n",
      "United Airlines Holding, said the fare applies to the Chicago route. Washington was born into slavery\n",
      "on the farm of James Burroughs. Washington went up 2 games to 1 in the four-game series. Blair\n",
      "arrived in Washington for what may well be his last state visit. In June, Washington passed a primary\n",
      "seatbelt law.\n"
     ]
    }
   ],
   "source": [
    "with open('article.txt', 'r') as file:\n",
    "    text1 = file.read()\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHh1uEZh6LS-"
   },
   "source": [
    "<font size=\"4\"><font face=\"Bookman Old Style\"><b>Question 2</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Sr4MgNHF5rol"
   },
   "outputs": [],
   "source": [
    "normalized_text = text1.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "D_BsVznb5wEz"
   },
   "outputs": [],
   "source": [
    "with open('article.txt', 'w') as file:\n",
    "    file.write(normalized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRggkMex5yeR",
    "outputId": "2e0e4387-caff-4259-8a5d-33497298ccf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "citing high fuel prices, united airlines said on friday, it has increased fares by $6 per round trip on\n",
      "flights to some cities also served by lower-cost carriers. american airlines, a unit of corp.,\n",
      "immediately matched the move, spokesman tim wagner said. united, a unit of corp., said the\n",
      "increase took effect on thursday and applies to most routes where it competes against discount\n",
      "carriers, such as chicago to dallas and denver to san francisco. jane villanueva of united, a unit of\n",
      "united airlines holding, said the fare applies to the chicago route. washington was born into slavery\n",
      "on the farm of james burroughs. washington went up 2 games to 1 in the four-game series. blair\n",
      "arrived in washington for what may well be his last state visit. in june, washington passed a primary\n",
      "seatbelt law.\n"
     ]
    }
   ],
   "source": [
    "with open('article.txt', 'r') as file:\n",
    "    text1 = file.read()\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nuk0fMjBEjMm"
   },
   "source": [
    "<font size=\"4\"><font face=\"Bookman Old Style\"><b>Question 3</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Kn3RsOY50sz",
    "outputId": "1523b508-5031-456a-d8cc-85ca7859414c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to article.txt\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = word_tokenize(text1)\n",
    "\n",
    "# Define the regex pattern to match punctuation\n",
    "pattern = r'[^\\w\\s]'\n",
    "\n",
    "# Remove punctuation using regex\n",
    "new_text1 = re.sub(pattern, '', text1)\n",
    "\n",
    "# Find the list of punctuations removed\n",
    "punc_removed = re.findall(pattern, text1)\n",
    "\n",
    "# Write results to a file\n",
    "output_file_path = \"article.txt\"\n",
    "\n",
    "with open('article.txt', 'w') as file:\n",
    "    file.write(new_text1+'\\n\\n')\n",
    "    file.write(str(punc_removed))\n",
    "\n",
    "print(\"Results written to\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Q3yyikIEpXk"
   },
   "source": [
    "<font size=\"4\"><font face=\"Bookman Old Style\"><b>Question 4</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_pDemp06_ne",
    "outputId": "357f3cfd-5dc6-48ec-c552-a713823983f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to stopword_lab3.txt\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Get the list of English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove stopwords\n",
    "no_stopwords = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "# List of stopwords\n",
    "stopwords_list = list(stop_words)\n",
    "\n",
    "# Write results to a file\n",
    "output_file_path = \"stopword_lab3.txt\"\n",
    "\n",
    "with open('stopword_lab3.txt', 'w') as file:\n",
    "    file.write(str(no_stopwords)+'\\n\\n')\n",
    "    file.write(str(stopwords_list))\n",
    "\n",
    "print(\"Results written to\", output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyLfmsqCGT7A"
   },
   "source": [
    "<font size=\"4\"><font face=\"Bookman Old Style\"><b>Question 5</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZANvG9KCc8y",
    "outputId": "f33b2672-032b-4c3b-f9c9-a360134a6373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to lab3_q5.txt\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "\n",
    "# Tokenize the text into sentences\n",
    "sentences = sent_tokenize(text1)\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = word_tokenize(text1)\n",
    "\n",
    "# Write results to a file\n",
    "output_file_path = \"lab3_q5.txt\"\n",
    "\n",
    "with open('lab3_q5.txt', 'w') as file:\n",
    "    file.write(\"Tokenized Sentences:\\n\")\n",
    "    for sentence in sentences:\n",
    "        file.write(sentence + '\\n')\n",
    "\n",
    "    file.write(\"\\nTokenized Words:\\n\")\n",
    "    for word in words:\n",
    "        file.write(word + '\\n')\n",
    "\n",
    "print(\"Results written to\", output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VyKDexN6IX_8"
   },
   "source": [
    "<font size=\"4\"><font face=\"Bookman Old Style\"><b>Question 6</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rIBChNqZG1Ic",
    "outputId": "a3e26b98-d256-4d2f-f55d-5723ddf2e00d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-stem pairs written to lab3_q6.txt\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = word_tokenize(text1)\n",
    "\n",
    "# Initialize Porter's stemming algorithm\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Create a list to store word-stem pairs\n",
    "word_stem_pairs = []\n",
    "\n",
    "# Perform stemming and create word-stem pairs\n",
    "for word in words:\n",
    "    stem = stemmer.stem(word)\n",
    "    word_stem_pairs.append((word, stem))\n",
    "\n",
    "# Write the list of word-stem pairs to a file\n",
    "output_file_path = \"lab3_q6.txt\"\n",
    "with open(output_file_path, \"w\") as f:\n",
    "    for word, stem in word_stem_pairs:\n",
    "        f.write(f\"{word}-{stem}\\n\")\n",
    "\n",
    "print(\"Word-stem pairs written to\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CdD-QEhJkAv"
   },
   "source": [
    "<font size=\"4\"><font face=\"Bookman Old Style\"><b>Question 7</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nse--JtpJVhw",
    "outputId": "c56d54df-fb8f-49c3-c8f4-9a95e8c07232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-lemma pairs written to lab3_q7.txt\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = word_tokenize(text1)\n",
    "\n",
    "# Initialize WordNet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Create a list to store word-lemma pairs\n",
    "word_lemma_pairs = []\n",
    "\n",
    "# Perform lemmatization and create word-lemma pairs\n",
    "for word in words:\n",
    "    lemma = lemmatizer.lemmatize(word)\n",
    "    word_lemma_pairs.append((word, lemma))\n",
    "\n",
    "# Write the list of word-lemma pairs to a file\n",
    "output_file_path = \"lab3_q7.txt\"\n",
    "with open(output_file_path, \"w\") as f:\n",
    "    for word, lemma in word_lemma_pairs:\n",
    "        f.write(f\"{word}-{lemma}\\n\")\n",
    "\n",
    "print(\"Word-lemma pairs written to\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dH9zVKMKut5"
   },
   "source": [
    "<font size=\"4\"><font face=\"Bookman Old Style\"><b>Question 8</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AdJeKYUjKBDz",
    "outputId": "8ccbbd29-82cd-405b-b775-e0e348ae35be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "citing-VBG\n",
      "high-JJ\n",
      "fuel-NN\n",
      "prices-NNS\n",
      ",-,\n",
      "united-JJ\n",
      "airlines-NNS\n",
      "said-VBD\n",
      "on-IN\n",
      "friday-NN\n",
      ",-,\n",
      "it-PRP\n",
      "has-VBZ\n",
      "increased-VBN\n",
      "fares-NNS\n",
      "by-IN\n",
      "$-$\n",
      "6-CD\n",
      "per-IN\n",
      "round-NN\n",
      "trip-NN\n",
      "on-IN\n",
      "flights-NNS\n",
      "to-TO\n",
      "some-DT\n",
      "cities-NNS\n",
      "also-RB\n",
      "served-VBN\n",
      "by-IN\n",
      "lower-cost-JJ\n",
      "carriers-NNS\n",
      ".-.\n",
      "american-JJ\n",
      "airlines-NNS\n",
      ",-,\n",
      "a-DT\n",
      "unit-NN\n",
      "of-IN\n",
      "corp.-NN\n",
      ",-,\n",
      "immediately-RB\n",
      "matched-VBD\n",
      "the-DT\n",
      "move-NN\n",
      ",-,\n",
      "spokesman-NN\n",
      "tim-NN\n",
      "wagner-NN\n",
      "said-VBD\n",
      ".-.\n",
      "united-JJ\n",
      ",-,\n",
      "a-DT\n",
      "unit-NN\n",
      "of-IN\n",
      "corp.-NN\n",
      ",-,\n",
      "said-VBD\n",
      "the-DT\n",
      "increase-NN\n",
      "took-VBD\n",
      "effect-NN\n",
      "on-IN\n",
      "thursday-NN\n",
      "and-CC\n",
      "applies-NNS\n",
      "to-TO\n",
      "most-JJS\n",
      "routes-NNS\n",
      "where-WRB\n",
      "it-PRP\n",
      "competes-VBZ\n",
      "against-IN\n",
      "discount-NN\n",
      "carriers-NNS\n",
      ",-,\n",
      "such-JJ\n",
      "as-IN\n",
      "chicago-NNS\n",
      "to-TO\n",
      "dallas-NNS\n",
      "and-CC\n",
      "denver-NN\n",
      "to-TO\n",
      "san-VB\n",
      "francisco-NN\n",
      ".-.\n",
      "jane-NN\n",
      "villanueva-NN\n",
      "of-IN\n",
      "united-JJ\n",
      ",-,\n",
      "a-DT\n",
      "unit-NN\n",
      "of-IN\n",
      "united-JJ\n",
      "airlines-NNS\n",
      "holding-VBG\n",
      ",-,\n",
      "said-VBD\n",
      "the-DT\n",
      "fare-NN\n",
      "applies-VBZ\n",
      "to-TO\n",
      "the-DT\n",
      "chicago-NN\n",
      "route-NN\n",
      ".-.\n",
      "washington-NN\n",
      "was-VBD\n",
      "born-VBN\n",
      "into-IN\n",
      "slavery-NN\n",
      "on-IN\n",
      "the-DT\n",
      "farm-NN\n",
      "of-IN\n",
      "james-NNS\n",
      "burroughs-NNS\n",
      ".-.\n",
      "washington-NN\n",
      "went-VBD\n",
      "up-RB\n",
      "2-CD\n",
      "games-NNS\n",
      "to-TO\n",
      "1-CD\n",
      "in-IN\n",
      "the-DT\n",
      "four-game-JJ\n",
      "series-NN\n",
      ".-.\n",
      "blair-NN\n",
      "arrived-VBD\n",
      "in-IN\n",
      "washington-NN\n",
      "for-IN\n",
      "what-WP\n",
      "may-MD\n",
      "well-RB\n",
      "be-VB\n",
      "his-PRP$\n",
      "last-JJ\n",
      "state-NN\n",
      "visit-NN\n",
      ".-.\n",
      "in-IN\n",
      "june-NN\n",
      ",-,\n",
      "washington-NN\n",
      "passed-VBD\n",
      "a-DT\n",
      "primary-JJ\n",
      "seatbelt-NN\n",
      "law-NN\n",
      ".-.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = word_tokenize(text1)\n",
    "\n",
    "# Perform parts-of-speech tagging\n",
    "pos_tags = pos_tag(words)\n",
    "\n",
    "# Print the list of word-POS pairs\n",
    "for word, pos in pos_tags:\n",
    "    print(f\"{word}-{pos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5BK72EiLEhZ"
   },
   "source": [
    "<font size=\"4\"><font face=\"Bookman Old Style\"><b>Question 9</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ARrR-fXK2jd",
    "outputId": "eb53be5b-c504-4d4b-9207-045a2ac9019b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6609a0cf5370>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Tokenize the text into words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Perform Named-Entity Recognition using ne_chunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import ne_chunk\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Perform Named-Entity Recognition using ne_chunk\n",
    "ne_tree = ne_chunk(nltk.pos_tag(words))\n",
    "\n",
    "# Function to extract word-NE pairs from the NLTK NE tree\n",
    "def extract_word_ne_pairs(tree):\n",
    "    word_ne_pairs = []\n",
    "    for subtree in tree:\n",
    "        if type(subtree) == nltk.Tree:\n",
    "            ne_label = subtree.label()\n",
    "            ne_words = \" \".join([word for word, _ in subtree])\n",
    "            word_ne_pairs.append((ne_words, ne_label))\n",
    "    return word_ne_pairs\n",
    "\n",
    "# Extract word-NE pairs and print them\n",
    "word_ne_pairs_nltk = extract_word_ne_pairs(ne_tree)\n",
    "for word, ne in word_ne_pairs_nltk:\n",
    "    print(f\"{word}-{ne}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1er6jnU9M23I",
    "outputId": "b7d8b11d-92e3-4c6a-ff0b-de454b6ce622"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United Airlines-ORG\n",
      "Friday-DATE\n",
      "6-MONEY\n",
      "American Airlines-ORG\n",
      "Corp.-GPE\n",
      "Tim Wagner-PERSON\n",
      "United-ORG\n",
      "Corp.-ORG\n",
      "Thursday-DATE\n",
      "Chicago-GPE\n",
      "Dallas-GPE\n",
      "Denver-GPE\n",
      "San Francisco-GPE\n",
      "Jane Villanueva-PERSON\n",
      "United-ORG\n",
      "United Airlines Holding-ORG\n",
      "Chicago-GPE\n",
      "Washington-GPE\n",
      "James Burroughs-PERSON\n",
      "Washington-GPE\n",
      "2-CARDINAL\n",
      "1-CARDINAL\n",
      "four-CARDINAL\n",
      "Blair-PERSON\n",
      "Washington-GPE\n",
      "June-DATE\n",
      "Washington-GPE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract word-NE pairs and print them\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text}-{ent.label_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "U1FcipDzNDcP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
