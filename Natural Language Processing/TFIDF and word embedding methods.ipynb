{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Bookman Old Style\"><font size=\"4\">Download HOD's message for the departments - Statistics, Computer Science,Mathematics and Physics from the website of CHRIST University. Demonstrate the following. \n",
    "1. Most Similar and different Messages using TFIDF and word embedding methods.\n",
    "2. Find Distinctiveness in the messages as list. Use WorNet to find synonyms and hypernyms to get distinctiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Department accentuates quality education with focus on research inclusive learning enabling students to find the best-suited possiblities for future careers.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phy = \"\"\"Department accentuates quality education with focus on research inclusive learning enabling students to find the best-suited possiblities for future careers.\"\"\"\n",
    "phy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The primary focus of our curriculum is to impart technical know-how to students, promote problem solving skills, ignite their research aptitude and trigger the interest in innovation of new technologies.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp = \"\"\"The primary focus of our curriculum is to impart technical know-how to students, promote problem solving skills, ignite their research aptitude and trigger the interest in innovation of new technologies.\"\"\"\n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Steadily growing with it's mission to organise, create, connect and communicate mathematical ideas effectively through the 4Ds: Dedication, Determination, Discipline and Direction.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maths = \"\"\"Steadily growing with it's mission to organise, create, connect and communicate mathematical ideas effectively through the 4Ds: Dedication, Determination, Discipline and Direction.\"\"\"\n",
    "maths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The world today, driven by a surge of data, much of it which is unfiltered, needs a statistician to make sense of it. Software can help in analysis but to draw conclusions, we need statisticians.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = \"\"\"The world today, driven by a surge of data, much of it which is unfiltered, needs a statistician to make sense of it. Software can help in analysis but to draw conclusions, we need statisticians.\"\"\"\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "phy_tokens = word_tokenize(phy.lower())\n",
    "comp_tokens = word_tokenize(comp.lower())\n",
    "maths_tokens = word_tokenize(maths.lower())\n",
    "ds_tokens = word_tokenize(ds.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Similarity:\n",
      "Similarity between Physics and Computer Science: 0.13\n",
      "Similarity between Physics and Mathematics: 0.06\n",
      "Similarity between Physics and Statistics: 0.03\n",
      "Similarity between Computer Science and Mathematics: 0.10\n",
      "Similarity between Computer Science and Statistics: 0.22\n",
      "Similarity between Mathematics and Statistics: 0.08\n",
      "Most Similar Departments: Physics and Physics\n",
      "Most Different Departments: Mathematics and Mathematics\n"
     ]
    }
   ],
   "source": [
    "#Question 1 - TFIDF\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform([phy, comp, maths, ds])\n",
    "\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "departments = [\"Physics\", \"Computer Science\", \"Mathematics\", \"Statistics\"]\n",
    "print(\"TF-IDF Similarity:\")\n",
    "for i in range(len(departments)):\n",
    "    for j in range(i+1, len(departments)):\n",
    "        similarity = cosine_sim[i][j]\n",
    "        print(f\"Similarity between {departments[i]} and {departments[j]}: {similarity:.2f}\")\n",
    "\n",
    "most_similar_idx = (cosine_sim + np.eye(4)).argmax()\n",
    "most_different_idx = (cosine_sim - np.eye(4)).argmin()\n",
    "most_similar_departments = (most_similar_idx // 4, most_similar_idx % 4)\n",
    "most_different_departments = (most_different_idx // 4, most_different_idx % 4)\n",
    "print(f\"Most Similar Departments: {departments[most_similar_departments[0]]} and {departments[most_similar_departments[1]]}\")\n",
    "print(f\"Most Different Departments: {departments[most_different_departments[0]]} and {departments[most_different_departments[1]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.31\n",
      "connect\n",
      "\n",
      "Similarity: 0.28\n",
      "growing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "messages = [phy, comp, maths, ds]\n",
    "messages_tokens = [message.lower().split() for message in messages]\n",
    "model = Word2Vec(sentences=messages_tokens, vector_size=100, window=5, min_count=1, sg=0)\n",
    "similar_messages = model.wv.most_similar('research', topn=2)\n",
    "for message, similarity in similar_messages:\n",
    "    print(f\"Similarity: {similarity:.2f}\")\n",
    "    print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinctiveness between Physics and Computer Science:\n",
      "Word: to\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Word: students\n",
      "Synonyms: scholar, student, pupil, educatee, bookman, scholarly_person\n",
      "Hypernyms: intellectual, enrollee\n",
      "\n",
      "Word: the\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Word: research\n",
      "Synonyms: explore, search, research, inquiry, enquiry\n",
      "Hypernyms: investigation, investigate, problem_solving\n",
      "\n",
      "Word: .\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Word: focus\n",
      "Synonyms: centre, focalise, focussing, center, focusing, rivet, focalize, centering, direction, focal_point, sharpen, pore, concenter, concentre, nidus, concentrate, stress, focus\n",
      "Hypernyms: concentration, clarity, emphasis, point, adjust, distinctness, sharpen, think, align\n",
      "\n",
      "Distinctiveness between Physics and Mathematics:\n",
      "Word: to\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Word: with\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Word: the\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Word: .\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Distinctiveness between Physics and Statistics:\n",
      "Word: to\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Word: the\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Word: .\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Distinctiveness between Computer Science and Mathematics:\n",
      "Word: to\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Word: the\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Word: and\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Word: ,\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Word: .\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Distinctiveness between Computer Science and Statistics:\n",
      "Word: to\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Word: the\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Word: ,\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Word: of\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Word: in\n",
      "Synonyms: inward, inwards, indium, Hoosier_State, Indiana, atomic_number_49, inch, IN, in, In\n",
      "Hypernyms: metallic_element, linear_unit\n",
      "\n",
      "Word: is\n",
      "Synonyms: constitute, make_up, comprise, personify, live, embody, cost, exist, be, represent, follow, equal\n",
      "Hypernyms: stay, take, typify, be\n",
      "\n",
      "Word: .\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Distinctiveness between Mathematics and Statistics:\n",
      "Word: to\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Word: the\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Word: ,\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n",
      "Word: it\n",
      "Synonyms: information_technology, IT\n",
      "Hypernyms: engineering\n",
      "\n",
      "Word: .\n",
      "Synonyms: \n",
      "Hypernyms: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Question 2\n",
    "\n",
    "departments = [\"Physics\", \"Computer Science\", \"Mathematics\", \"Statistics\"]\n",
    "\n",
    "def find_synonyms_hypernyms(word):\n",
    "    synonyms = set()\n",
    "    hypernyms = set()\n",
    "    for synset in wordnet.synsets(word):\n",
    "        for lemma in synset.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "        for hypernym in synset.hypernyms():\n",
    "            hypernyms.add(hypernym.name().split('.')[0])\n",
    "    return list(synonyms), list(hypernyms)\n",
    "\n",
    "distinctiveness = {}\n",
    "messages_tokens = [phy_tokens, comp_tokens, maths_tokens, ds_tokens]\n",
    "\n",
    "for i in range(len(departments)):\n",
    "    for j in range(i + 1, len(departments)):\n",
    "        message1_tokens = messages_tokens[i]\n",
    "        message2_tokens = messages_tokens[j]\n",
    "        common_words = set(message1_tokens).intersection(message2_tokens)\n",
    "        word_synonyms_hypernyms = {}\n",
    "        for word in common_words:\n",
    "            synonyms, hypernyms = find_synonyms_hypernyms(word)\n",
    "            word_synonyms_hypernyms[word] = {\"synonyms\": synonyms, \"hypernyms\": hypernyms}\n",
    "        distinctiveness[(departments[i], departments[j])] = word_synonyms_hypernyms\n",
    "        \n",
    "for (dept1, dept2), words in distinctiveness.items():\n",
    "    print(f\"Distinctiveness between {dept1} and {dept2}:\")\n",
    "    for word, info in words.items():\n",
    "        synonyms = info[\"synonyms\"]\n",
    "        hypernyms = info[\"hypernyms\"]\n",
    "        print(f\"Word: {word}\")\n",
    "        print(f\"Synonyms: {', '.join(synonyms)}\")\n",
    "        print(f\"Hypernyms: {', '.join(hypernyms)}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
